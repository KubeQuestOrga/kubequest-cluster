# Flapi - Cluster K3s - High Availability 

## üõ† Tech Stack

- **Ansible**: Automatise le d√©ploiement des noeud master / worker sur les serveurs.
- **CI/CD (GitHub Actions)**: Automatise le processus de d√©ploiement des noeuds worker / master.

<br /><br /><br /><br />


## üìö Documentation 

### Cr√©ation du Cluster K3s

#### 1. Connexion au VPS / Serveur D√©di√©
Connectez-vous √† votre serveur qui servira de premier n≈ìud master dans votre cluster K3s.

#### 2. Cr√©ation et Initialisation du Premier N≈ìud Master
1. Ex√©cutez la commande suivante pour initialiser le cluster K3s et cr√©er le premier n≈ìud master :
```bash
curl -sfL https://get.k3s.io | sh -s - server --cluster-init --disable traefik --node-taint CriticalAddonsOnly=true:NoExecute --tls-san cluster-k3s.crzcommon.com
```
2. Configurer le nombre de snapshots conserv√©s (checker plus bas l'√©tape est d√©crite dans Sauvegarde et Restauration du Cluster K3s)

#### Explications des Flags :
- `server` : Ce flag indique que le n≈ìud sera initialis√© comme un serveur dans le cluster K3s. Cela signifie qu'il agira comme un n≈ìud master, g√©rant l'√©tat du cluster et ex√©cutant des composants du plan de contr√¥le tels que l'API server, le scheduler, et le controller manager.
- `--cluster-init` : Initialise un nouveau cluster K3s. Ce flag est n√©cessaire lors de la cr√©ation du premier serveur dans un cluster K3s pour mettre en place le plan de contr√¥le et pr√©parer le cluster √† joindre d'autres serveurs ou agents.
- `--disable traefik` : D√©sactive l'installation automatique de Traefik, qui est l'ingress controller par d√©faut inclus avec K3s. Vous pouvez choisir de d√©sactiver Traefik si vous pr√©voyez d'utiliser un autre ingress controller ou si vous n'avez pas besoin de cette fonctionnalit√©.
- `--node-taint CriticalAddonsOnly=true:NoExecute` : Applique un taint au n≈ìud serveur, ce qui emp√™che les pods qui n'ont pas de tol√©rance correspondante d'√™tre planifi√©s sur ce n≈ìud. Ce taint est souvent utilis√© pour s'assurer que seuls les pods critiques pour le fonctionnement du cluster soient ex√©cut√©s sur les n≈ìuds serveur, aidant √† garder ces n≈ìuds stables et s√©curis√©s.
- `--tls-san cluster-k3s.crzcommon.com` : Ajoute un Subject Alternative Name (SAN) au certificat TLS g√©n√©r√© pour l'API server de Kubernetes. Cela permet d'acc√©der en toute s√©curit√© √† l'API server via le nom de domaine sp√©cifi√© (cluster-k3s.crzcommon.com dans cet exemple), en plus de son adresse IP. C'est crucial pour les environnements o√π vous acc√©dez √† l'API server de Kubernetes √† travers un r√©seau ou Internet.

<br /><br />

### Joindre de Nouveaux N≈ìuds au Cluster K3s

#### 1. Obtenir le `K3S_TOKEN` pour Joindre le Cluster
```bash
# Sur le n≈ìud master
sudo chmod 644 /var/lib/rancher/k3s/server/ && sudo cat /var/lib/rancher/k3s/server/token
```

#### 2. A faire avant de rejoindre le Cluster K3s
1. `ATTENTION` : Avant d'essayer de rejoindre le cluster K3S, il faut voir si le nom de domaine est bien r√©solu depuis la machine qui veut rejoindre.
```bash
# Erreur :
debian@vps-7b992047:~$ curl -k https://cluster-k3s.crzcommon.com:6443
curl: (6) Could not resolve host: cluster-k3s.crzcommon.com

# Valide :
debian@vps-370a6b62:~$ curl -k https://cluster-k3s.crzcommon.com:6443
{
  "kind": "Status",
  "apiVersion": "v1",
  "metadata": {},
  "status": "Failure",
  "message": "Unauthorized",
  "reason": "Unauthorized",
  "code": 401
}
```
Si c'est en erreur, il faudrai ajout√© dans /etc/hosts pour r√©soudre le domaine dans certains cas (ajouter l'ip du loadbalancer pour le domaine) :
```bash
sudo nano /etc/hosts

# Ajouter cette ligne au fichier
149.202.48.239 cluster-k3s.crzcommon.com
```
2. `ATTENTION` : Avant de rejoindre le cluster K3S, il faut absolument le SUPPRIMER du cluster r√©ellement avant qu'il puisse rejoindre √† nouveau,
c'est possible qu'ont ce retrouve avec des probl√®mes pour rejoindre ! Donc il vaut mieux le supprimer du cluster si l'ip √©tait d√©j√† connu auparavant du cluster. <br />
Command : `sudo kubectl delete node <name-node>` (depuis un autre noeud master actif)

#### 3. Joindre un N≈ìud Master au Cluster K3s 
1. Commande pour rejoindre le cluster K3s en tant que noeud MASTER :
```bash
curl -sfL https://get.k3s.io | K3S_TOKEN=xxx sh -s - server --server https://cluster-k3s.crzcommon.com:6443 --disable traefik --node-taint CriticalAddonsOnly=true:NoExecute --tls-san cluster-k3s.crzcommon.com
```
2. Configurer le nombre de snapshots conserv√©s (checker plus bas l'√©tape est d√©crite dans Sauvegarde et Restauration du Cluster K3s)

#### 4. Joindre un N≈ìud Worker au Cluster K3s
1. Commande pour rejoindre le cluster K3s en tant que noeud WORKER :
```bash
curl -sfL https://get.k3s.io | K3S_TOKEN=xxx sh -s - agent --server https://cluster-k3s.crzcommon.com:6443
```

#### 5. Apr√®s avoir rejoindre SI JAMAIS il y a une erreur
`ATTENTION`: Si vous avez l'erreur ci-dessous, il est possible que le noeud vas quand m√™me rejoindre patienter jusqu'a 5min.
```bash
Job for k3s.service failed because the control process exited with error code.
See "systemctl status k3s.service" and "journalctl -xeu k3s.service" for details.
```

#### 6. Configuration Syst√®me et Conseils
- **D√©sactiver le Swap (vps pas possible)** : Important pour les performances et la stabilit√© de Kubernetes.
- **Nombre Impair de N≈ìuds Master** : N√©cessaire pour maintenir le quorum en cas de panne.
- **Noms d'H√¥tes Uniques** : Chaque n≈ìud dans le cluster doit avoir un nom d'h√¥te unique.
- **Utiliser des Disques SSD pour les N≈ìuds Master** : Recommand√© pour de meilleures performances et une latence r√©duite.
- **D√©sactiver le parefeu (Ubuntu/Debian)** : `ufw disable`
- **Mettre √† jour le syst√®me**: `sudo apt update && sudo apt upgrade -y`

<br /><br />

### Mise √† jour de la version Kubernetes sur les noeuds
1. Se connecter sur un noeud.
2. Run command : 
```bash
curl -sfL https://get.k3s.io | INSTALL_K3S_CHANNEL=stable sh -
```
3. Check si la mont√© de version c'est bien fait :
```bash
sudo kubectl get node -o wide
```

<br /><br />

### Haute Disponibilit√© du Cluster K3s

#### Un cluster HA K3s avec etcd int√©gr√© est compos√© de :
- Trois n≈ìuds de serveur ou plus qui serviront l'API Kubernetes et ex√©cuteront d'autres services de plan de contr√¥le, ainsi qu'h√©bergeront la banque de donn√©es etcd int√©gr√©e. 
- Facultatif : z√©ro ou plusieurs n≈ìuds d'agent d√©sign√©s pour ex√©cuter vos applications et services
- Facultatif : une adresse d'enregistrement fixe (load balancer) pour que les n≈ìuds d'agent / worker s'inscrivent aupr√®s du cluster (Voir le projet : https://github.com/CrzGames/Crzgames_LoadBalancer_External)

<br /><br />

### Get KUBECONFIG :
1. Connect to the NODE MASTER in the Cluster K3S.
2. Run command, copy kubeconfig : 
```bash
sudo cat /etc/rancher/k3s/k3s.yaml
```
3. Replace "127.0.0.1:6443" to " https://cluster-k3s.crzcommon.com:6443".
4. Encode BASE64 and add in SECRETS VARIABLE for CI / CD, run command :
```bash
sudo base64 /etc/rancher/k3s/k3s.yaml > k3s_base64.txt 
```

<br /><br />

## Sauvegarde et Restauration du Cluster K3s
### Par d√©fault
- K3s cr√©e des `snapshots etcd automatiques`.
- K3s cr√©e les snapshots etcd automatique √† `00h00` et `12h00`
- K3s `conserve` les `5 derniers snapshots`.
- K3s conserve les snapshots dans : `/var/lib/rancher/k3s/server/db/snapshots`.
- Lorsque K3s est restaur√© √† partir d'une sauvegarde, l'ancien r√©pertoire de donn√©es (`/var/lib/rancher/k3s/server/db/snapshots`) est d√©plac√© vers `/var/lib/rancher/k3s/server/db/etcd-old/`. K3s tente ensuite de restaurer l'instantan√© en cr√©ant un nouveau r√©pertoire de donn√©es, puis en d√©marrant etcd avec un nouveau cluster K3s avec un membre etcd.

### Configurer le nombre de snapshots conserv√©s (√† faire sur chaque noeud master)
```bash
# Ajoutez l'option '--etcd-snapshot-retention=10' √† la ligne ExecStart :
sudo nano /etc/systemd/system/k3s.service
# Recharger le daemon systemd pour appliquer les modifications :
sudo systemctl daemon-reload
# Arreter et d√©marrer √† nouveau K3s :
sudo systemctl stop k3s
sudo systemctl start k3s
```

### Cr√©ation d'un Snapshot etcd Manuel
```bash
sudo k3s etcd-snapshot save
# save is : /var/lib/rancher/k3s/server/db/snapshots
```

### Liste des Snapshots
```bash
sudo k3s etcd-snapshot ls
```

### Restaurer un Cluster K3s
1. Sur le premier n≈ìud (Server1), arr√™ter et d√©marrer K3s avec les options de r√©initialisation du cluster :
```bash
sudo systemctl stop k3s
sudo k3s server \
  --cluster-reset \
  --cluster-reset-restore-path=/var/lib/rancher/k3s/server/db/snapshots/mysnapshot
```
2. Sur les autres n≈ìuds (Server2, Server3), arr√™tez K3s et supprimez le r√©pertoire de donn√©es :
```bash
sudo systemctl stop k3s
sudo rm -rf /var/lib/rancher/k3s/server/db/
```
3. Sur le premier n≈ìud (Sever1), red√©marrez K3s :
```bash
sudo systemctl start k3s
```
4. Sur les autres n≈ìuds (Server2, Server3), red√©marrez K3s pour rejoindre le cluster restaur√© :
```bash
sudo systemctl start k3s
```

<br /><br /><br /><br />


## üöÄ Production
### ‚öôÔ∏è‚û°Ô∏è Processus de distribution automatique (CI / CD)
#### Configuration Initiale pour un Nouveau Projet

1. **Cr√©er le Cluster K3S**: Il faudra au pr√©alable avoir cr√©e manuellement le cluster K3S, voir tout en haut du fichier 'README.md' pour plus de d√©tails.

2. **Configuration des secrets GitHub**:

   Pour la configuration initiale, assurez-vous d'ajouter les secrets suivants dans votre d√©p√¥t GitHub :

   - `CLUSTER_SSH_PRIVATE_KEY`: Votre cl√© priv√©e SSH. Cette cl√© doit correspondre √† la cl√© publique d√©j√† install√©e sur les serveurs cibles.
   - `CLUSTER_SSH_HOSTS`: Les adresses IP des serveurs cibles, s√©par√©es par des espaces. <br />
   Exemple : `192.0.2.1 198.51.100.2`. Ces adresses seront utilis√©es pour pr√©parer le fichier `known_hosts`, facilitant ainsi des connexions SSH s√©curis√©es.
   - `CLUSTER_K3S_TOKEN`: Token pour s'authentifier au pr√®s du cluster K3S, on peut le r√©cup√©rer `via` un `noeud master` : <br />
    ```bash
    sudo chmod 644 /var/lib/rancher/k3s/server/ && sudo cat /var/lib/rancher/k3s/server/token
    ```

3. **Ajout de la cl√© publique sur les serveurs cibles**:

   Avant de pouvoir d√©ployer automatiquement via CI/CD, la cl√© publique associ√©e √† `CLUSTER_SSH_PRIVATE_KEY` doit √™tre ajout√©e au fichier `~/.ssh/authorized_keys` sur chaque serveur cible. Cette √©tape garantit que GitHub Actions peut se connecter aux serveurs via SSH sans intervention manuelle.
